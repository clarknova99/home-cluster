---
# yaml-language-server: $schema=https://raw.githubusercontent.com/fluxcd-community/flux2-schemas/main/helmrelease-helm-v2beta2.json
apiVersion: helm.toolkit.fluxcd.io/v2beta2
kind: HelmRelease
metadata:
  name: sparknova
  namespace: default
spec:
  interval: 15m
  chart:
    spec:
      chart: app-template
      version: 2.4.0
      sourceRef:
        kind: HelmRepository
        name: bjw-s
        namespace: flux-system
      interval: 15m
  maxHistory: 3
  install:
    remediation:
      retries: 5
  upgrade:
    remediation:
      retries: 5
  ## If you're reading this, please know I have no idea what I'm doing and learning as I go along. Highly likely this is not the preferred method for deploying Spark on Kubernetes
  values:
    controllers:
      main:
        type: statefulset
        annotations:
          reloader.stakater.com/auto: "true"
        containers:
          main:
            image:
              repository: docker.io/clarknova9/spark
              tag: 3.5.0-scala2.12-v1.0.1@sha256:dc0a6f3ff1a44961f43e655d51394619e8908869f59db51b92765a6cc68d7a07
            imagePullPolicy: Always
            command: ["/opt/spark/bin/spark-class","org.apache.spark.deploy.master.Master"]
            ports:
              - name: http
                containerPort: 8080
                protocol: TCP
              - name: cluster
                containerPort: 7077
                protocol: TCP
              - name: rest
                containerPort: 6066
                protocol: TCP
            env:
              SPARK_MODE: master
              SPARK_MASTER_PORT: "7077"
              SPARK_MASTER_WEBUI_PORT: "8080"
        pod:
          nodeSelector:
            kubernetes.io/arch: amd64
            #kubernetes.io/hostname: aurora
      spark-worker-1:
        type: deployment
        replicas: 1
        containers:
          spark-worker-1:
            image:
              repository: docker.io/clarknova9/spark
              tag: 3.5.0-scala2.12-v1.0.1@sha256:dc0a6f3ff1a44961f43e655d51394619e8908869f59db51b92765a6cc68d7a07
            imagePullPolicy: IfNotPresent
            command: ["/opt/spark/bin/spark-class","org.apache.spark.deploy.worker.Worker", "spark://sparknova-spark-master-svc:7077"]
            ports:
              - name: http
                containerPort: 8081
                protocol: TCP
            env:
              SPARK_MODE: worker
              SPARK_MASTER_URL: spark://sparknova-spark-master-svc:7077
              SPARK_WORKER_MEMORY: 4G
              SPARK_WORKER_CORES: "2"
              SPARK_WORKER_WEBUI_PORT: "8081"
        pod:
          nodeSelector:
            kubernetes.io/arch: amd64
      spark-worker-2:
        type: deployment
        replicas: 1
        containers:
          spark-worker-1:
            image:
              repository: docker.io/clarknova9/spark
              tag: 3.5.0-scala2.12-v1.0.1@sha256:dc0a6f3ff1a44961f43e655d51394619e8908869f59db51b92765a6cc68d7a07
            imagePullPolicy: IfNotPresent
            command: ["/opt/spark/bin/spark-class","org.apache.spark.deploy.worker.Worker", "spark://sparknova-spark-master-svc:7077"]
            ports:
              - name: http
                containerPort: 8081
                protocol: TCP
            env:
              SPARK_MODE: worker
              SPARK_MASTER_URL: spark://sparknova-spark-master-svc:7077
              SPARK_WORKER_MEMORY: 4G
              SPARK_WORKER_CORES: "2"
              SPARK_WORKER_WEBUI_PORT: "8081"
        pod:
          nodeSelector:
            kubernetes.io/arch: amd64
      spark-worker-3:
        type: deployment
        replicas: 1
        containers:
          spark-worker-3:
            image:
              repository: docker.io/clarknova9/spark
              tag: 3.5.0-scala2.12-v1.0.1@sha256:dc0a6f3ff1a44961f43e655d51394619e8908869f59db51b92765a6cc68d7a07
            imagePullPolicy: IfNotPresent
            command: ["/opt/spark/bin/spark-class","org.apache.spark.deploy.worker.Worker", "spark://sparknova-spark-master-svc:7077"]
            ports:
              - name: http
                containerPort: 8081
                protocol: TCP
            env:
              SPARK_MODE: worker
              SPARK_MASTER_URL: spark://sparknova-spark-master-svc:7077
              SPARK_WORKER_MEMORY: 4G
              SPARK_WORKER_CORES: "2"
              SPARK_WORKER_WEBUI_PORT: "8081"
        pod:
          nodeSelector:
            kubernetes.io/arch: amd64
      jupyter:
        type: deployment
        replicas: 1
        containers:
          jupyter:
            image:
              repository: docker.io/clarknova9/spark
              tag: 3.5.0-scala2.12-v1.0.1@sha256:dc0a6f3ff1a44961f43e655d51394619e8908869f59db51b92765a6cc68d7a07
            imagePullPolicy: IfNotPresent
            command: ["jupyter", "lab", "--allow-root", "--ip=0.0.0.0", "--NotebookApp.token=", "--no-browser", "--ServerApp.root_dir=/opt/workspace"]
            ports:
              - name: http
                containerPort: 8888
                protocol: TCP
        pod:
          nodeSelector:
            kubernetes.io/arch: amd64
      kyuubi:
        type: deployment
        replicas: 1
        containers:
          kyuubi:
            image:
              repository: docker.io/clarknova9/spark
              tag: 3.5.0-scala2.12-v1.0.1@sha256:dc0a6f3ff1a44961f43e655d51394619e8908869f59db51b92765a6cc68d7a07
            imagePullPolicy: IfNotPresent
            command: ["/opt/kyuubi/bin/kyuubi", "run"]
            ports:
              - name: http
                containerPort: 10009
                protocol: TCP
              - name: thrift
                containerPort: 10000
                protocol: TCP
            env:
              kyuubi.engineEnv.SPARK_DRIVER_MEMORY: 4g
              kyuubi.engineEnv.SPARK_DRIVER_CORES: "2"
              kyuubi.engineEnv.SPARK_EXECUTOR_MEMORY: 2g
              kyuubi.engineEnv.SPARK_EXECUTOR_CORES: "2"
        pod:
          nodeSelector:
            kubernetes.io/arch: amd64
    service:
      main:
        annotations:
          io.cilium/lb-ipam-ips: "192.168.2.100"
        externalTrafficPolicy: Cluster
        type: LoadBalancer
        #type: ClusterIP
        # -- Override the name suffix that is used for this service
        nameOverride: spark-master-svc
        # -- Provide additional labels which may be required.
        labels:
          app: sparknova
        ports:
          http:
            port: 8080
          cluster:
            protocol: TCP
            port: 7077
            targetPort: 7077
          rest:
            protocol: TCP
            port: 6066
            targetPort: 6066
      spark-worker-1:
        controller: spark-worker-1
        # -- Override the name suffix that is used for this service
        nameOverride: spark-worker-1-svc
        # -- Provide additional labels which may be required.
        labels:
          app: sparknova
        ports:
          spark-worker-1:
            protocol: TCP
            port: 8081
            targetPort: 8081
      spark-worker-2:
        controller: spark-worker-2
        # -- Override the name suffix that is used for this service
        nameOverride: spark-worker-2-svc
        # -- Provide additional labels which may be required.
        labels:
          app: sparknova
        ports:
          spark-worker-2:
            protocol: TCP
            port: 8081
            targetPort: 8081
      spark-worker-3:
        controller: spark-worker-3
        # -- Override the name suffix that is used for this service
        nameOverride: spark-worker-3-svc
        # -- Provide additional labels which may be required.
        labels:
          app: sparknova
        ports:
          spark-worker-2:
            protocol: TCP
            port: 8081
            targetPort: 8081
      jupyter:
        controller: jupyter
        # -- Override the name suffix that is used for this service
        nameOverride: jupyter-svc
        # -- Provide additional labels which may be required.
        labels:
          app: sparknova
        ports:
          jupyter:
            protocol: TCP
            port: 8888
            targetPort: 8888
      kyuubi:
        annotations:
          io.cilium/lb-ipam-ips: "192.168.2.101"
        externalTrafficPolicy: Cluster
        type: LoadBalancer
        controller: kyuubi
        # -- Override the name suffix that is used for this service
        nameOverride: kyuubi-svc
        # -- Provide additional labels which may be required.
        labels:
          app: sparknova
        ports:
          kyuubi:
            protocol: TCP
            port: 10009
            targetPort: 10009
      thrift:
        annotations:
          io.cilium/lb-ipam-ips: "192.168.2.102"
        externalTrafficPolicy: Cluster
        type: LoadBalancer
        controller: kyuubi
        # -- Override the name suffix that is used for this service
        nameOverride: thrift-svc
        # -- Provide additional labels which may be required.
        labels:
          app: sparknova
        ports:
          thrift:
            protocol: TCP
            port: 10000
            targetPort: 10000
    ingress:
      main:
        enabled: true
        ingressClassName: internal
        annotations:
          hajimari.io/icon: mdi:creation
        hosts:
          - host: spark.${SECRET_DOMAIN}
            paths:
              - path: /
                pathType: Prefix
                service:
                  name: main
                  port: http
        tls:
          - hosts:
              - spark.${SECRET_DOMAIN}
      jupyter:
        enabled: true
        ingressClassName: internal
        hosts:
          - host: jupyter.${SECRET_DOMAIN}
            paths:
              - path: /
                pathType: Prefix
                service:
                  name: sparknova-jupyter-svc
                  port: 8888
        tls:
          - hosts:
              - jupyter.${SECRET_DOMAIN}
    persistence:
      config-file:
        type: configMap
        name: spark-config
        globalMounts:
          - path: /opt/spark/conf/spark-defaults.conf
            subPath: spark-defaults.conf
            readOnly: true
      kyuubi-config:
        type: configMap
        name: kyuubi-config
        globalMounts:
          - path: /opt/kyuubi/conf/kyuubi-defaults.conf
            subPath: kyuubi-defaults.conf
            readOnly: true
      warehouse:
        enabled: true
        type: nfs
        server: 192.168.1.2
        path: /volume1/network-storage/sparknova/spark-warehouse
        globalMounts:
          - path: /opt/spark-warehouse
      sparkcatalog:
        enabled: true
        type: nfs
        server: 192.168.1.2
        path: /volume1/network-storage/sparknova/spark_catalog
        globalMounts:
          - path: /opt/spark_catalog
      workspace:
        enabled: true
        type: nfs
        server: 192.168.1.2
        path: /volume1/network-storage/sparknova/workspace
        globalMounts:
          - path: /opt/workspace
      kyuubi-work:
        enabled: true
        type: nfs
        server: 192.168.1.2
        path: /volume1/network-storage/sparknova/kyuubi/work
        globalMounts:
          - path: /opt/kyuubi/work
      logs:
        enabled: true
        type: nfs
        server: 192.168.1.2
        path: /volume1/network-storage/sparknova/logs
        globalMounts:
          - path: /opt/spark/logs
