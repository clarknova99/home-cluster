---
# yaml-language-server: $schema=https://raw.githubusercontent.com/fluxcd-community/flux2-schemas/main/helmrelease-helm-v2beta2.json
apiVersion: helm.toolkit.fluxcd.io/v2beta2
kind: HelmRelease
metadata:
  name: sparknova
  namespace: default
spec:
  interval: 15m
  chart:
    spec:
      chart: app-template
      version: 2.4.0
      sourceRef:
        kind: HelmRepository
        name: bjw-s
        namespace: flux-system
      interval: 15m
  maxHistory: 3
  install:
    remediation:
      retries: 5
  upgrade:
    remediation:
      retries: 5
  ## If you're reading this, please know I have no idea what I'm doing and learning as I go along. Highly likely this is not the preferred method for deploying Spark on Kubernetes
  values:
    controllers:
      main:
        type: statefulset
        annotations:
          reloader.stakater.com/auto: "true"
        containers:
          main:
            image:
              repository: docker.io/clarknova9/sparknova
              tag: 0.0.0@sha256:f85378768c13d35613ff94909e6f73044a53f6ec56384c2c3c6d2bc4870d902e
            imagePullPolicy: Always
            command: ["/opt/spark/bin/spark-class","org.apache.spark.deploy.master.Master"]
            ports:
              - name: http
                containerPort: 8080
                protocol: TCP
              - name: cluster
                containerPort: 7077
                protocol: TCP
              - name: rest
                containerPort: 6066
                protocol: TCP
            env:
              SPARK_MODE: master
              SPARK_MASTER_PORT: "7077"
              SPARK_MASTER_WEBUI_PORT: "8080"
          jupyter:
            image:
              repository: docker.io/clarknova9/sparknova
              tag: 0.0.0@sha256:f85378768c13d35613ff94909e6f73044a53f6ec56384c2c3c6d2bc4870d902e
            imagePullPolicy: Always
            command: ["jupyter", "lab", "--allow-root", "--ip=0.0.0.0", "--NotebookApp.token=", "--no-browser", "--ServerApp.root_dir=/opt/workspace"]
            ports:
              - name: jupyter
                containerPort: 8888
                protocol: TCP
          kyuubi:
            image:
              repository: docker.io/clarknova9/sparknova
              tag: 0.0.0@sha256:f85378768c13d35613ff94909e6f73044a53f6ec56384c2c3c6d2bc4870d902e
            imagePullPolicy: Always
            command: ["/opt/kyuubi/bin/kyuubi", "run"]
            ports:
              - name: http
                containerPort: 10009
                protocol: TCP
              - name: thrift
                containerPort: 10000
                protocol: TCP
            env:
              kyuubi.engineEnv.SPARK_DRIVER_MEMORY: 4g
              kyuubi.engineEnv.SPARK_DRIVER_CORES: "2"
              kyuubi.engineEnv.SPARK_EXECUTOR_MEMORY: 2g
              kyuubi.engineEnv.SPARK_EXECUTOR_CORES: "2"
          spark-worker-1:
            image:
              repository: docker.io/clarknova9/sparknova
              tag: 0.0.0@sha256:f85378768c13d35613ff94909e6f73044a53f6ec56384c2c3c6d2bc4870d902e
            imagePullPolicy: Always
            command: ["/opt/spark/bin/spark-class","org.apache.spark.deploy.worker.Worker", "spark://sparknova-spark-master-svc:7077"]
            ports:
              - name: http
                containerPort: 8081
                protocol: TCP
            env:
              SPARK_MODE: worker
              SPARK_MASTER_URL: spark://sparknova-spark-master-svc:7077
              SPARK_WORKER_MEMORY: 4G
              SPARK_WORKER_CORES: "2"
              SPARK_WORKER_WEBUI_PORT: "8081"
          spark-worker-2:
            image:
              repository: docker.io/clarknova9/sparknova
              tag: 0.0.0@sha256:f85378768c13d35613ff94909e6f73044a53f6ec56384c2c3c6d2bc4870d902e
            imagePullPolicy: Always
            command: ["/opt/spark/bin/spark-class","org.apache.spark.deploy.worker.Worker", "spark://sparknova-spark-master-svc:7077"]
            ports:
              - name: http
                containerPort: 8081
                protocol: TCP
            env:
              SPARK_MODE: worker
              SPARK_MASTER_URL: spark://sparknova-spark-master-svc:7077
              SPARK_WORKER_MEMORY: 4G
              SPARK_WORKER_CORES: "2"
              SPARK_WORKER_WEBUI_PORT: "8081"
          # spark-worker-3:
          #   image:
          #     repository: docker.io/clarknova9/sparknova
          #     tag: 0.0.0@sha256:f85378768c13d35613ff94909e6f73044a53f6ec56384c2c3c6d2bc4870d902e
          #   imagePullPolicy: IfNotPresent
          #   command: ["/opt/spark/bin/spark-class","org.apache.spark.deploy.worker.Worker", "spark://sparknova-spark-master-svc:7077"]
          #   ports:
          #     - name: http
          #       containerPort: 8081
          #       protocol: TCP
          #   env:
          #     SPARK_MODE: worker
          #     SPARK_MASTER_URL: spark://sparknova-spark-master-svc:7077
          #     SPARK_WORKER_MEMORY: 4G
          #     SPARK_WORKER_CORES: "2"
          #     SPARK_WORKER_WEBUI_PORT: "8081"
        pod:
          nodeSelector:
            kubernetes.io/arch: amd64
            #kubernetes.io/hostname: aurora
          # securityContext:
          #   runAsUser: 185
          #   runAsGroup: 185
          #   fsGroup: 185
          #   fsGroupChangePolicy: OnRootMismatch
      spark-worker-3:
        type: deployment
        replicas: 1
        containers:
          spark-worker-3:
            image:
              repository: docker.io/clarknova9/sparknova
              tag: 0.0.0@sha256:f85378768c13d35613ff94909e6f73044a53f6ec56384c2c3c6d2bc4870d902e
            imagePullPolicy: IfNotPresent
            command: ["/opt/spark/bin/spark-class","org.apache.spark.deploy.worker.Worker", "spark://sparknova-spark-master-svc.default.svc.cluster.local:7077"]
            ports:
              - name: http
                containerPort: 8081
                protocol: TCP
            env:
              SPARK_MODE: worker
              SPARK_MASTER_URL: spark://sparknova-spark-master-svc:7077
              SPARK_WORKER_MEMORY: 4G
              SPARK_WORKER_CORES: "2"
              SPARK_WORKER_WEBUI_PORT: "8081"
        pod:
          nodeSelector:
            kubernetes.io/arch: amd64
      # spark-worker-2:
      #   type: deployment
      #   replicas: 1
      #   containers:
      #     spark-worker-1:
      #       image:
      #         repository: docker.io/clarknova9/spark
      #         tag: 3.5.0-scala2.12-v1.0.1@sha256:dc0a6f3ff1a44961f43e655d51394619e8908869f59db51b92765a6cc68d7a07
      #       imagePullPolicy: IfNotPresent
      #       command: ["/opt/spark/bin/spark-class","org.apache.spark.deploy.worker.Worker", "spark://sparknova-spark-master-svc:7077"]
      #       ports:
      #         - name: http
      #           containerPort: 8081
      #           protocol: TCP
      #       env:
      #         SPARK_MODE: worker
      #         SPARK_MASTER_URL: spark://sparknova-spark-master-svc:7077
      #         SPARK_WORKER_MEMORY: 4G
      #         SPARK_WORKER_CORES: "2"
      #         SPARK_WORKER_WEBUI_PORT: "8081"
      #   pod:
      #     nodeSelector:
      #       kubernetes.io/arch: amd64
      # spark-worker-3:
      #   type: deployment
      #   replicas: 1
      #   containers:
      #     spark-worker-3:
      #       image:
      #         repository: docker.io/clarknova9/spark
      #         tag: 3.5.0-scala2.12-v1.0.1@sha256:dc0a6f3ff1a44961f43e655d51394619e8908869f59db51b92765a6cc68d7a07
      #       imagePullPolicy: IfNotPresent
      #       command: ["/opt/spark/bin/spark-class","org.apache.spark.deploy.worker.Worker", "spark://sparknova-spark-master-svc:7077"]
      #       ports:
      #         - name: http
      #           containerPort: 8081
      #           protocol: TCP
      #       env:
      #         SPARK_MODE: worker
      #         SPARK_MASTER_URL: spark://sparknova-spark-master-svc:7077
      #         SPARK_WORKER_MEMORY: 4G
      #         SPARK_WORKER_CORES: "2"
      #         SPARK_WORKER_WEBUI_PORT: "8081"
      #   pod:
      #     nodeSelector:
      #       kubernetes.io/arch: amd64
      # jupyter:
      #   type: deployment
      #   replicas: 1
      #   containers:
      #     jupyter:
      #       image:
      #         repository: docker.io/clarknova9/spark
      #         tag: 3.5.0-scala2.12-v1.0.1@sha256:dc0a6f3ff1a44961f43e655d51394619e8908869f59db51b92765a6cc68d7a07
      #       imagePullPolicy: IfNotPresent
      #       command: ["jupyter", "lab", "--allow-root", "--ip=0.0.0.0", "--NotebookApp.token=", "--no-browser", "--ServerApp.root_dir=/opt/workspace"]
      #       ports:
      #         - name: http
      #           containerPort: 8888
      #           protocol: TCP
      #   pod:
      #     nodeSelector:
      #       kubernetes.io/arch: amd64
      # kyuubi:
      #   type: deployment
      #   replicas: 1
      #   containers:
      #     kyuubi:
      #       image:
      #         repository: docker.io/clarknova9/spark
      #         tag: 3.5.0-scala2.12-v1.0.1@sha256:dc0a6f3ff1a44961f43e655d51394619e8908869f59db51b92765a6cc68d7a07
      #       imagePullPolicy: IfNotPresent
      #       command: ["/opt/kyuubi/bin/kyuubi", "run"]
      #       ports:
      #         - name: http
      #           containerPort: 10009
      #           protocol: TCP
      #         - name: thrift
      #           containerPort: 10000
      #           protocol: TCP
      #       env:
      #         kyuubi.engineEnv.SPARK_DRIVER_MEMORY: 4g
      #         kyuubi.engineEnv.SPARK_DRIVER_CORES: "2"
      #         kyuubi.engineEnv.SPARK_EXECUTOR_MEMORY: 2g
      #         kyuubi.engineEnv.SPARK_EXECUTOR_CORES: "2"
      #   pod:
      #     nodeSelector:
      #       kubernetes.io/arch: amd64
    serviceAccount:
      create: false
      name: sparknova
    service:
      main:
        annotations:
          io.cilium/lb-ipam-ips: "192.168.2.100"
        externalTrafficPolicy: Cluster
        type: LoadBalancer
        #type: ClusterIP
        # -- Override the name suffix that is used for this service
        nameOverride: spark-master-svc
        # -- Provide additional labels which may be required.
        labels:
          app: sparknova
        ports:
          http:
            port: 8080
          cluster:
            protocol: TCP
            port: 7077
            targetPort: 7077
          rest:
            protocol: TCP
            port: 6066
            targetPort: 6066
      jupyter:
        controller: main
        # -- Override the name suffix that is used for this service
        nameOverride: jupyter-svc
        # -- Provide additional labels which may be required.
        labels:
          app: sparknova
        ports:
          jupyter:
            protocol: TCP
            port: 8888
            targetPort: 8888
      kyuubi:
        annotations:
          io.cilium/lb-ipam-ips: "192.168.2.101"
        externalTrafficPolicy: Cluster
        type: LoadBalancer
        controller: main
        # -- Override the name suffix that is used for this service
        nameOverride: kyuubi-svc
        # -- Provide additional labels which may be required.
        labels:
          app: sparknova
        ports:
          kyuubi:
            protocol: TCP
            port: 10009
            targetPort: 10009
      thrift:
        annotations:
          io.cilium/lb-ipam-ips: "192.168.2.102"
        externalTrafficPolicy: Cluster
        type: LoadBalancer
        controller: main
        # -- Override the name suffix that is used for this service
        nameOverride: thrift-svc
        # -- Provide additional labels which may be required.
        labels:
          app: sparknova
        ports:
          thrift:
            protocol: TCP
            port: 10000
            targetPort: 10000
    ingress:
      main:
        enabled: true
        ingressClassName: internal
        annotations:
          hajimari.io/icon: mdi:creation
        hosts:
          - host: spark.${SECRET_DOMAIN}
            paths:
              - path: /
                pathType: Prefix
                service:
                  name: main
                  port: http
        tls:
          - hosts:
              - spark.${SECRET_DOMAIN}
      jupyter:
        enabled: true
        ingressClassName: internal
        hosts:
          - host: jupyter.${SECRET_DOMAIN}
            paths:
              - path: /
                pathType: Prefix
                service:
                  name: sparknova-jupyter-svc
                  port: 8888
        tls:
          - hosts:
              - jupyter.${SECRET_DOMAIN}
    persistence:
      tmp:
        enabled: true
        storageClass: local-hostpath
        accessMode: ReadWriteOnce
        retain: false
        size: 5Gi
        globalMounts:
          - path: /tmp
            readOnly: false
      config-file:
        type: configMap
        name: spark-config
        globalMounts:
          - path: /opt/spark/conf/spark-defaults.conf
            subPath: spark-defaults.conf
            readOnly: true
      kyuubi-config:
        type: configMap
        name: kyuubi-config
        globalMounts:
          - path: /opt/kyuubi/conf/kyuubi-defaults.conf
            subPath: kyuubi-defaults.conf
            readOnly: true
      warehouse:
        enabled: true
        type: nfs
        server: 192.168.1.2
        path: /volume1/network-storage/sparknova/spark-warehouse
        globalMounts:
          - path: /opt/spark-warehouse
      sparkcatalog:
        enabled: true
        type: nfs
        server: 192.168.1.2
        path: /volume1/network-storage/sparknova/spark_catalog
        globalMounts:
          - path: /opt/spark_catalog
      workspace:
        enabled: true
        type: nfs
        server: 192.168.1.2
        path: /volume1/network-storage/sparknova/workspace
        globalMounts:
          - path: /opt/workspace
      kyuubi-work:
        enabled: true
        type: nfs
        server: 192.168.1.2
        path: /volume1/network-storage/sparknova/kyuubi/work
        globalMounts:
          - path: /opt/kyuubi/work
      logs:
        enabled: true
        type: nfs
        server: 192.168.1.2
        path: /volume1/network-storage/sparknova/logs
        globalMounts:
          - path: /opt/spark/logs
